{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eba3f59c-7a37-4b07-ac7b-4345ff7bcef4",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "**Maddy Bursell, Kim McKeever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93118b84-ab2e-4010-9368-4c3f2f813510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "import warnings\n",
    "import math\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c0b213",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, we will be reading in files that use US census data from the years 1987-2006. The goal will be to first read in the data and parse it into a format we can use. We will do this using a series of functions for data processing and combining data. We are interested in seeing if certain variables like year and census geographic division can predict the number of students enrolled in public school. Later, we will use the data to make a simple linear regression model and a multiple linear regression model and use cross-validation and estimate the Mean-squared error to see which model works better for predicting enrollment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fe8e3f",
   "metadata": {},
   "source": [
    "## Part 1: Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f2f65",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd47657-beca-45b4-812b-38e7ea9dcefa",
   "metadata": {},
   "source": [
    "First, we read in the initial census data to examine using `pd.read_csv()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c53331e-f72f-4098-b820-e36fe5ceef83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area_name</th>\n",
       "      <th>STCOU</th>\n",
       "      <th>EDU010187F</th>\n",
       "      <th>EDU010187D</th>\n",
       "      <th>EDU010187N1</th>\n",
       "      <th>EDU010187N2</th>\n",
       "      <th>EDU010188F</th>\n",
       "      <th>EDU010188D</th>\n",
       "      <th>EDU010188N1</th>\n",
       "      <th>EDU010188N2</th>\n",
       "      <th>...</th>\n",
       "      <th>EDU010194N1</th>\n",
       "      <th>EDU010194N2</th>\n",
       "      <th>EDU010195F</th>\n",
       "      <th>EDU010195D</th>\n",
       "      <th>EDU010195N1</th>\n",
       "      <th>EDU010195N2</th>\n",
       "      <th>EDU010196F</th>\n",
       "      <th>EDU010196D</th>\n",
       "      <th>EDU010196N1</th>\n",
       "      <th>EDU010196N2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40024299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39967624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43993459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44715737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>733735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>728234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>727989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>736825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autauga, AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>6829</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baldwin, AL</td>\n",
       "      <td>1003</td>\n",
       "      <td>0</td>\n",
       "      <td>16417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barbour, AL</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>5071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Area_name  STCOU  EDU010187F  EDU010187D  EDU010187N1  EDU010187N2  \\\n",
       "0  UNITED STATES      0           0    40024299            0            0   \n",
       "1        ALABAMA   1000           0      733735            0            0   \n",
       "2    Autauga, AL   1001           0        6829            0            0   \n",
       "3    Baldwin, AL   1003           0       16417            0            0   \n",
       "4    Barbour, AL   1005           0        5071            0            0   \n",
       "\n",
       "   EDU010188F  EDU010188D  EDU010188N1  EDU010188N2  ...  EDU010194N1  \\\n",
       "0           0    39967624            0            0  ...            0   \n",
       "1           0      728234            0            0  ...            0   \n",
       "2           0        6900            0            0  ...            0   \n",
       "3           0       16465            0            0  ...            0   \n",
       "4           0        5098            0            0  ...            0   \n",
       "\n",
       "   EDU010194N2  EDU010195F  EDU010195D  EDU010195N1  EDU010195N2  EDU010196F  \\\n",
       "0            0           0    43993459            0            0           0   \n",
       "1            0           0      727989            0            0           0   \n",
       "2            0           0        7568            0            0           0   \n",
       "3            0           0       19961            0            0           0   \n",
       "4            0           0        5017            0            0           0   \n",
       "\n",
       "   EDU010196D  EDU010196N1  EDU010196N2  \n",
       "0    44715737            0            0  \n",
       "1      736825            0            0  \n",
       "2        7834            0            0  \n",
       "3       20699            0            0  \n",
       "4        5053            0            0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_data = pd.read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv\")\n",
    "import_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339dc0ab",
   "metadata": {},
   "source": [
    "We can see that the data contains many columns and many different kinds of variables within columns. It will be helpful to clean up the data to be more understandable before we begin to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba390b",
   "metadata": {},
   "source": [
    "### Create functions to clean and process the data\n",
    "\n",
    "Functions can be extremely useful when you want to process multiple files in the same way. In this section, we will define 5 different functions that will be called in one wrapper function. All of the functions will work to select only the specific columns we want, create new columns we need, and format the data how we want it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef9d53a",
   "metadata": {},
   "source": [
    "In **data_processing_1** we first want to clean up the data by selecting only certain columns and renaming one column. Our step one will be to rename the \"Area_name\" column as \"area_name\" and to grab all of the columns that end in the letter \"D.\" To do this, it is easiest to create a function that we can use on other datasets down the line. In this function, we take in a dataframe as the input and we have an optional argument to name the new column. The default name of the new column is \"enrollment.\" \n",
    "\n",
    "We only want to maintain a few columns with specific parameters: we want 'Area_name', 'STCOU', and any column that ends with the letter 'D'. Since we want to select all columns ending in \"D\", we are locating those names first. Creating a list of desired columns for our modified data frame by using specific coumn names from the import data and by unpacking the list of column names that end with \"D\" that was generated in the previous line. Next, using the `.loc()` method and the desired columns found in 'col_list', we add those columns to our dataframe. Lastly, we will convert our data into long format where each row has only one enrollment value for the column area_name. This will help to get rid of multiple observations in a given row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45dff0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_1(df_1, col_name = \"enrollment\"):\n",
    "    \n",
    "    # Change the column name\n",
    "    df_2 = df_1.rename(columns = {\"Area_name\":\"area_name\"}, inplace = True)\n",
    "    \n",
    "    # Create a list of the column names and an empty list to grab all of the columns ending in \"D\"\n",
    "    cols=list(df_1)\n",
    "    col_names=[]\n",
    "    \n",
    "    # We will use a for loop to iterate through the columns and grab the column names ending in \"D\" into a list\n",
    "    for x in cols:\n",
    "        if x.endswith(\"D\"):\n",
    "            col_names.append(x)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    # We can subset our original dataframe to grab the columns we want with the list \"col_list\"\n",
    "    col_list=['area_name', 'STCOU', *col_names]\n",
    "    df_2=df_1.loc[:,col_list]\n",
    "    \n",
    "    # Convert the dataframe to long format using pd.melt()\n",
    "    df_2 = df_2.melt(id_vars = [\"area_name\", \"STCOU\"], var_name = \"info\", value_name = col_name)\n",
    "    \n",
    "    return(df_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b36b86b",
   "metadata": {},
   "source": [
    "In **data_processing_2**, we are taking the output of *data_processing_1* and processing it even more. Each variable in the info column holds important information. The last two characters before the \"D\" represent the year. We want to create a new column called \"year\" that stores the year. The first three characters represent the survey and the next four represent the type of value you have from the survey. We want to capture those first seven characters in another column called \"measurement.\"\n",
    "\n",
    "First, we will create new empty columns in our dataframe. Then, we will loop through the dataframe by the row, find the info column value, and parse out the measurment and the year. The value for each row will be added to the new columns of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fcf6d7-c7d0-4342-8eaf-f64366c8c8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_2(df_2): \n",
    "    # Create empty columns for year and measurement\n",
    "    df_2[\"year\"] = np.nan\n",
    "    df_2[\"measurement\"] = np.nan\n",
    "    \n",
    "    # Make a loop to grab the first 7 elements for each row in the info column and put it in the new \n",
    "    # measurement column\n",
    "    for row in range(len(df_2)):\n",
    "        thing = df_2.loc[row, \"info\"]\n",
    "        measure = thing[0:7]\n",
    "        \n",
    "        # We are pulling out the two-digit year numbers and making it a four-digit year\n",
    "        if int(thing[7:9])>=23:\n",
    "            yr = \"19\" + str(thing[7:9])\n",
    "        else:\n",
    "            yr= '20'+ str(thing[7:9])\n",
    "        df_2.loc[row,\"year\"] = int(yr)\n",
    "        df_2.loc[row,\"measurement\"] = str(measure)\n",
    "        \n",
    "    return(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66a418",
   "metadata": {},
   "source": [
    "In the **data_processing_3** function, we are only editing the county-level data. This function will be called within a later function (*data_processing_5*) once we have split our original dataframe into two new dataframes called county_df and non_county_df. In *data_processing_3*, we are taking the county_df and creating a new column in it where we have the state for each row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6a716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_3(dataframe):\n",
    "    \n",
    "    # Making a new column called state that stores the last two characters of area_name\n",
    "    dataframe[\"State\"] = dataframe.loc[:,\"area_name\"].apply(lambda x: x[-2:])\n",
    "    \n",
    "    return(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c351e1",
   "metadata": {},
   "source": [
    "In **data_processing_4**, we are editing only the state-level data. This function will be called in data_processing_5, after we have created the two new dataframes called county_df and non_county_df. In this function, we will be creating a new column in non_county_df that includes the census division that each of the states falls into. We do this by using a function within a function called *return_div*. This will check if the state is in a certain list, and return the census division to the new column in the dataframe using np.vectorize(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f2d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_4(dataframe):\n",
    "    \n",
    "    # This function checks for each state, which division it falls into by looking for the state in a list\n",
    "    def return_div(val):\n",
    "        div1 = [\"CONNECTICUT\", 'MAINE','MASSACHUSETTS','NEW HAMPSHIRE','RHODE ISLAND','VERMONT']\n",
    "        div2 = [\"NEW JERSEY\",'NEW YORK','PENNSYLVANIA']\n",
    "        div3 = ['ILLINOIS','INDIANA','MICHIGAN','OHIO','WISCONSIN']\n",
    "        div4 = ['IOWA','KANSAS','MINNESOTA','MISSOURI','NEBRASKA','NORTH DAKOTA','SOUTH DAKOTA']\n",
    "        div5 = ['DELAWARE','FLORIDA','GEORGIA','MARYLAND','NORTH CAROLINA','SOUTH CAROLINA','VIRGINIA',\n",
    "                'DISTRICT OF COLUMBIA','WEST VIRGINIA']\n",
    "        div6 = ['ALABAMA','KENTUCKY','MISSISSIPPI','TENNESSEE']\n",
    "        div7 = ['ARKANSAS','LOUISIANA','OKLAHOMA','TEXAS']\n",
    "        div8 = ['ARIZONA','COLORADO','IDAHO','NEVADA','MONTANA','NEW MEXICO','UTAH','WYOMING']\n",
    "        div9 = ['ALASKA','CALIFORNIA','HAWAII','OREGON','WASHINGTON']\n",
    "        val = val.upper()\n",
    "    \n",
    "        if val in div1:\n",
    "            return(\"Division 1\")\n",
    "        elif val in div2:\n",
    "            return(\"Division 2\")\n",
    "        elif val in div3:\n",
    "            return(\"Division 3\")\n",
    "        elif val in div4:\n",
    "            return(\"Division 4\")\n",
    "        elif val in div5:\n",
    "            return(\"Division 5\")\n",
    "        elif val in div6:\n",
    "            return(\"Division 6\")\n",
    "        elif val in div7:\n",
    "            return(\"Division 7\")\n",
    "        elif val in div8:\n",
    "            return(\"Division 8\")\n",
    "        elif val in div9:\n",
    "            return(\"Division 9\")\n",
    "        else:\n",
    "            return(\"ERROR\")\n",
    "        \n",
    "    dataframe[\"division\"] = np.vectorize(return_div)(dataframe[\"area_name\"])\n",
    "    return(dataframe)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c109afc9",
   "metadata": {},
   "source": [
    "In **data_processing_5**, we are processing the output from *data_processing_2* and creating two new dataframes. We can see that the \"area_name\" column holds two different kinds of values: states and other (ex: \"ALABAMA\" or \"UNITED STATES\") and counties of states (ex: \"Baldwin, AL\"). \n",
    "\n",
    "We would like to create two separate dataframes that hold the non-county-level data and the county-level data. To do that, we will create an indexing vector using a lambda function. The lambda function is searching the string within each row, in the 'area_name' column, searching to match if the fourth character of from the end is a `','`. \n",
    "\n",
    "This information is passed into a new column on the data frame that expresses a boolean to identify whether or not the row represented is part of a county or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062d098d-8e99-4b24-a347-0af0e7978a11",
   "metadata": {},
   "source": [
    "Now that there is a new column in the dataframe to index whether or not an area represents a county or not, the two different dataframes are created. The county data frame is generated using `.loc()` and the non_county dataframe is generated by running `np.logical_not()` method from numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3f485-ca33-41a0-b576-ca2045611a08",
   "metadata": {},
   "source": [
    "The State information was then pulled from the `area_name` column to be held in its own unique column called \"State\" in the county df. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befba0f6",
   "metadata": {},
   "source": [
    "Once we have the two new dataframes, we will call **data_processing_3** on county_df which will add a column called \"state\" specifying the state in each row. We will also call **data_processing_4** on non_county_df which will add a new column in that dataframe that specifies the division of each state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef225780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_5(dataframe):\n",
    "    \n",
    "    # Making a new column to index whether or not the values in a row are counties or other (non_county)\n",
    "    dataframe[\"is_county\"] = dataframe[\"area_name\"].apply(lambda x: x[-4] == \",\")\n",
    "    \n",
    "    # Used the new column to subset our original dataframe into two new dataframes\n",
    "    county_df = dataframe.loc[dataframe[\"is_county\"]]\n",
    "    non_county_df = dataframe.loc[np.logical_not(dataframe[\"is_county\"])]\n",
    "    \n",
    "    # Called some of our functions on the county data\n",
    "    county_df = data_processing_3(county_df)\n",
    "    final_county_df = county_df[[\"area_name\", \"STCOU\", \"enrollment\", \"year\", \"measurement\", \"State\"]]\n",
    "    \n",
    "    # Called some of our functions on the non_county data\n",
    "    non_county_df = data_processing_4(non_county_df)\n",
    "    final_non_county_df = non_county_df[[\"area_name\", \"STCOU\", \"enrollment\", \"year\", \"measurement\", \"division\"]]\n",
    "    \n",
    "    # We returned only the final versions with the columns we want to keep\n",
    "    return(final_county_df, final_non_county_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e034b",
   "metadata": {},
   "source": [
    "### Create a wrapper function that will call all of our previously defined functions\n",
    "\n",
    "If we have several functions that function continuously, meaning the output of one function becomes the input of the next function, we can easily run all of these functions at once by putting them within another function. This saves time and energy, and keeps you from making mistakes while typing in the input for each individual function. In our wrapper function, we give the argument for the data to read in and then all of the functions will run, leaving us with our desired output. Because the wrapper function combines all of our data processing functions, we have named it \"data_processing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dfe1b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(URL, col_name = \"enrollment\"):\n",
    "    \n",
    "    # Calling all of our data processing functions (some of them are functions within functions)\n",
    "    import_data = pd.read_csv(URL)\n",
    "    census_df = data_processing_1(import_data)\n",
    "    census_df_2 = data_processing_2(census_df)\n",
    "    final_county_df, final_non_county_df = data_processing_5(census_df_2)\n",
    "    \n",
    "    return([final_county_df, final_non_county_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e0ac8",
   "metadata": {},
   "source": [
    "We named the output from the first URL \"file_1_list.\" We called the wrapper function and used the URL as the argument. The output of our function is a list of the two dataframes. The first dataframe includes county data. The second dataframe includes non-county data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31428a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001        6829  1987.0     EDU0101    AL\n",
       " 3         Baldwin, AL   1003       16417  1987.0     EDU0101    AL\n",
       " 4         Barbour, AL   1005        5071  1987.0     EDU0101    AL\n",
       " 5            Bibb, AL   1007        3557  1987.0     EDU0101    AL\n",
       " 6          Blount, AL   1009        7319  1987.0     EDU0101    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037        9599  1996.0     EDU0101    WY\n",
       " 31976       Teton, WY  56039        2226  1996.0     EDU0101    WY\n",
       " 31977       Uinta, WY  56041        5750  1996.0     EDU0101    WY\n",
       " 31978    Washakie, WY  56043        1900  1996.0     EDU0101    WY\n",
       " 31979      Weston, WY  56045        1479  1996.0     EDU0101    WY\n",
       " \n",
       " [31450 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0    40024299  1987.0     EDU0101       ERROR\n",
       " 1            ALABAMA   1000      733735  1987.0     EDU0101  Division 6\n",
       " 69            ALASKA   2000      102872  1987.0     EDU0101  Division 9\n",
       " 99           ARIZONA   4000      609411  1987.0     EDU0101  Division 8\n",
       " 115         ARKANSAS   5000      429260  1987.0     EDU0101  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     1079854  1996.0     EDU0101  Division 5\n",
       " 31787     WASHINGTON  53000      956572  1996.0     EDU0101  Division 9\n",
       " 31827  WEST VIRGINIA  54000      307112  1996.0     EDU0101  Division 5\n",
       " 31883      WISCONSIN  55000      870175  1996.0     EDU0101  Division 3\n",
       " 31956        WYOMING  56000       99859  1996.0     EDU0101  Division 8\n",
       " \n",
       " [530 rows x 6 columns]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_1_list = data_processing(\"https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv\")\n",
    "file_1_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebaa338",
   "metadata": {},
   "source": [
    "We named the output from our second URL \"file_2_list.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "393a3a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001        8099  1997.0     EDU0101    AL\n",
       " 3         Baldwin, AL   1003       21410  1997.0     EDU0101    AL\n",
       " 4         Barbour, AL   1005        5100  1997.0     EDU0101    AL\n",
       " 5            Bibb, AL   1007        3717  1997.0     EDU0101    AL\n",
       " 6          Blount, AL   1009        7816  1997.0     EDU0101    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037        6964  2006.0     EDU0152    WY\n",
       " 31976       Teton, WY  56039        2264  2006.0     EDU0152    WY\n",
       " 31977       Uinta, WY  56041        4298  2006.0     EDU0152    WY\n",
       " 31978    Washakie, WY  56043        1410  2006.0     EDU0152    WY\n",
       " 31979      Weston, WY  56045        1076  2006.0     EDU0152    WY\n",
       " \n",
       " [31450 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0    44534459  1997.0     EDU0101       ERROR\n",
       " 1            ALABAMA   1000      737386  1997.0     EDU0101  Division 6\n",
       " 69            ALASKA   2000      129919  1997.0     EDU0101  Division 9\n",
       " 99           ARIZONA   4000      798069  1997.0     EDU0101  Division 8\n",
       " 115         ARKANSAS   5000      459787  1997.0     EDU0101  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     1220440  2006.0     EDU0152  Division 5\n",
       " 31787     WASHINGTON  53000     1026774  2006.0     EDU0152  Division 9\n",
       " 31827  WEST VIRGINIA  54000      281938  2006.0     EDU0152  Division 5\n",
       " 31883      WISCONSIN  55000      876700  2006.0     EDU0152  Division 3\n",
       " 31956        WYOMING  56000       85193  2006.0     EDU0152  Division 8\n",
       " \n",
       " [530 rows x 6 columns]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_2_list = data_processing(\"https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv\")\n",
    "file_2_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0822a5da",
   "metadata": {},
   "source": [
    "## Part 2: Combine Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fd69c5",
   "metadata": {},
   "source": [
    "### Combine county and state data from multiple files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3811d7",
   "metadata": {},
   "source": [
    "We want to combine our county dataframes non-county dataframes from two separate URLs. To do this, we wrote a function that takes unlimited positional arguments of the list output from our *data_processing* function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c15c4a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(*files):\n",
    "    \n",
    "    # Use lambda function to select the county and non-county dataframes from the list input\n",
    "    county_data = map(lambda x: x[0], files)\n",
    "    non_county_data = map(lambda x: x[1], files)\n",
    "    \n",
    "    # Use lambda function to concatenate the county and non-county data from multiple input file lists\n",
    "    combine_county = functools.reduce(lambda x,y: pd.concat([x,y]), county_data)\n",
    "    combine_non_county = functools.reduce(lambda x,y: pd.concat([x,y]), non_county_data)\n",
    "    \n",
    "    return([combine_county, combine_non_county])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ff8f4",
   "metadata": {},
   "source": [
    "We call our *combine_data* function on the two file lists we produced from our *data_processing* function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0f1f199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001        6829  1987.0     EDU0101    AL\n",
       " 3         Baldwin, AL   1003       16417  1987.0     EDU0101    AL\n",
       " 4         Barbour, AL   1005        5071  1987.0     EDU0101    AL\n",
       " 5            Bibb, AL   1007        3557  1987.0     EDU0101    AL\n",
       " 6          Blount, AL   1009        7319  1987.0     EDU0101    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037        6964  2006.0     EDU0152    WY\n",
       " 31976       Teton, WY  56039        2264  2006.0     EDU0152    WY\n",
       " 31977       Uinta, WY  56041        4298  2006.0     EDU0152    WY\n",
       " 31978    Washakie, WY  56043        1410  2006.0     EDU0152    WY\n",
       " 31979      Weston, WY  56045        1076  2006.0     EDU0152    WY\n",
       " \n",
       " [62900 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0    40024299  1987.0     EDU0101       ERROR\n",
       " 1            ALABAMA   1000      733735  1987.0     EDU0101  Division 6\n",
       " 69            ALASKA   2000      102872  1987.0     EDU0101  Division 9\n",
       " 99           ARIZONA   4000      609411  1987.0     EDU0101  Division 8\n",
       " 115         ARKANSAS   5000      429260  1987.0     EDU0101  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     1220440  2006.0     EDU0152  Division 5\n",
       " 31787     WASHINGTON  53000     1026774  2006.0     EDU0152  Division 9\n",
       " 31827  WEST VIRGINIA  54000      281938  2006.0     EDU0152  Division 5\n",
       " 31883      WISCONSIN  55000      876700  2006.0     EDU0152  Division 3\n",
       " 31956        WYOMING  56000       85193  2006.0     EDU0152  Division 8\n",
       " \n",
       " [1060 rows x 6 columns]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_enrollment = combine_data(file_1_list, file_2_list)\n",
    "combined_enrollment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d46ed9",
   "metadata": {},
   "source": [
    "### Check if it generalizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01825ab",
   "metadata": {},
   "source": [
    "We have seen that our data processing functions work on the files from URLs labeled \"EDU01a\" and \"EDU01b\", now we will check to see if our functions are generalized enough to work on multiple new files. We will import 4 new files using their URLs. \n",
    "\n",
    "Let's begin by running our wrapping function *data_processing* on the four new files to create 4 lists of county and non-county dataframes. We will name these additional files \"test\" so that we can distinguish them from the main two files we have been working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f67f5fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001       25508  1971.0     PST0151    AL\n",
       " 3         Baldwin, AL   1003       60141  1971.0     PST0151    AL\n",
       " 4         Barbour, AL   1005       23092  1971.0     PST0151    AL\n",
       " 5            Bibb, AL   1007       13919  1971.0     PST0151    AL\n",
       " 6          Blount, AL   1009       27817  1971.0     PST0151    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037       44284  1981.0     PST0251    WY\n",
       " 31976       Teton, WY  56039       10015  1981.0     PST0251    WY\n",
       " 31977       Uinta, WY  56041       16277  1981.0     PST0251    WY\n",
       " 31978    Washakie, WY  56043        9927  1981.0     PST0251    WY\n",
       " 31979      Weston, WY  56045        7508  1981.0     PST0251    WY\n",
       " \n",
       " [31450 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0   206827028  1971.0     PST0151       ERROR\n",
       " 1            ALABAMA   1000     3497452  1971.0     PST0151  Division 6\n",
       " 69            ALASKA   2000      316494  1971.0     PST0151  Division 9\n",
       " 99           ARIZONA   4000     1896108  1971.0     PST0151  Division 8\n",
       " 115         ARKANSAS   5000     1972028  1971.0     PST0151  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     5444155  1981.0     PST0251  Division 5\n",
       " 31787     WASHINGTON  53000     4235733  1981.0     PST0251  Division 9\n",
       " 31827  WEST VIRGINIA  54000     1954105  1981.0     PST0251  Division 5\n",
       " 31883      WISCONSIN  55000     4726315  1981.0     PST0251  Division 3\n",
       " 31956        WYOMING  56000      491700  1981.0     PST0251  Division 8\n",
       " \n",
       " [530 rows x 6 columns]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 = data_processing(\"https://www4.stat.ncsu.edu/~online/datasets/PST01a.csv\")\n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d018e8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001       32038  1982.0     PST0251    AL\n",
       " 3         Baldwin, AL   1003       82330  1982.0     PST0251    AL\n",
       " 4         Barbour, AL   1005       24775  1982.0     PST0251    AL\n",
       " 5            Bibb, AL   1007       16017  1982.0     PST0251    AL\n",
       " 6          Blount, AL   1009       36356  1982.0     PST0251    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037       38792  1990.0     PST0351    WY\n",
       " 31976       Teton, WY  56039       11328  1990.0     PST0351    WY\n",
       " 31977       Uinta, WY  56041       18638  1990.0     PST0351    WY\n",
       " 31978    Washakie, WY  56043        8363  1990.0     PST0351    WY\n",
       " 31979      Weston, WY  56045        6506  1990.0     PST0351    WY\n",
       " \n",
       " [31450 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0   231665106  1982.0     PST0251       ERROR\n",
       " 1            ALABAMA   1000     3925328  1982.0     PST0251  Division 6\n",
       " 69            ALASKA   2000      449608  1982.0     PST0251  Division 9\n",
       " 99           ARIZONA   4000     2889877  1982.0     PST0251  Division 8\n",
       " 115         ARKANSAS   5000     2294297  1982.0     PST0251  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     6216884  1990.0     PST0351  Division 5\n",
       " 31787     WASHINGTON  53000     4903043  1990.0     PST0351  Division 9\n",
       " 31827  WEST VIRGINIA  54000     1792548  1990.0     PST0351  Division 5\n",
       " 31883      WISCONSIN  55000     4904562  1990.0     PST0351  Division 3\n",
       " 31956        WYOMING  56000      453690  1990.0     PST0351  Division 8\n",
       " \n",
       " [530 rows x 6 columns]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2 = data_processing(\"https://www4.stat.ncsu.edu/~online/datasets/PST01b.csv\")\n",
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f38f47dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001       35010  1991.0     PST0351    AL\n",
       " 3         Baldwin, AL   1003      102420  1991.0     PST0351    AL\n",
       " 4         Barbour, AL   1005       26506  1991.0     PST0351    AL\n",
       " 5            Bibb, AL   1007       17071  1991.0     PST0351    AL\n",
       " 6          Blount, AL   1009       40190  1991.0     PST0351    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037       37613  2000.0     PST0402    WY\n",
       " 31976       Teton, WY  56039       18250  2000.0     PST0402    WY\n",
       " 31977       Uinta, WY  56041       19742  2000.0     PST0402    WY\n",
       " 31978    Washakie, WY  56043        8291  2000.0     PST0402    WY\n",
       " 31979      Weston, WY  56045        6644  2000.0     PST0402    WY\n",
       " \n",
       " [31450 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0   252980941  1991.0     PST0351       ERROR\n",
       " 1            ALABAMA   1000     4099156  1991.0     PST0351  Division 6\n",
       " 69            ALASKA   2000      570193  1991.0     PST0351  Division 9\n",
       " 99           ARIZONA   4000     3788576  1991.0     PST0351  Division 8\n",
       " 115         ARKANSAS   5000     2383144  1991.0     PST0351  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     7079048  2000.0     PST0402  Division 5\n",
       " 31787     WASHINGTON  53000     5894143  2000.0     PST0402  Division 9\n",
       " 31827  WEST VIRGINIA  54000     1808344  2000.0     PST0402  Division 5\n",
       " 31883      WISCONSIN  55000     5363708  2000.0     PST0402  Division 3\n",
       " 31956        WYOMING  56000      493783  2000.0     PST0402  Division 8\n",
       " \n",
       " [530 rows x 6 columns]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3 = data_processing(\"https://www4.stat.ncsu.edu/~online/datasets/PST01c.csv\")\n",
    "test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7288943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001       43872  2000.0     PST0452    AL\n",
       " 3         Baldwin, AL   1003      141358  2000.0     PST0452    AL\n",
       " 4         Barbour, AL   1005       29035  2000.0     PST0452    AL\n",
       " 5            Bibb, AL   1007       19936  2000.0     PST0452    AL\n",
       " 6          Blount, AL   1009       51181  2000.0     PST0452    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037       41226  2009.0     PST0452    WY\n",
       " 31976       Teton, WY  56039       20710  2009.0     PST0452    WY\n",
       " 31977       Uinta, WY  56041       20927  2009.0     PST0452    WY\n",
       " 31978    Washakie, WY  56043        7911  2009.0     PST0452    WY\n",
       " 31979      Weston, WY  56045        7009  2009.0     PST0452    WY\n",
       " \n",
       " [31450 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0   282171957  2000.0     PST0452       ERROR\n",
       " 1            ALABAMA   1000     4451849  2000.0     PST0452  Division 6\n",
       " 69            ALASKA   2000      627499  2000.0     PST0452  Division 9\n",
       " 99           ARIZONA   4000     5166697  2000.0     PST0452  Division 8\n",
       " 115         ARKANSAS   5000     2678288  2000.0     PST0452  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     7882590  2009.0     PST0452  Division 5\n",
       " 31787     WASHINGTON  53000     6664195  2009.0     PST0452  Division 9\n",
       " 31827  WEST VIRGINIA  54000     1819777  2009.0     PST0452  Division 5\n",
       " 31883      WISCONSIN  55000     5654774  2009.0     PST0452  Division 3\n",
       " 31956        WYOMING  56000      544270  2009.0     PST0452  Division 8\n",
       " \n",
       " [530 rows x 6 columns]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_4 = data_processing(\"https://www4.stat.ncsu.edu/~online/datasets/PST01d.csv\")\n",
    "test_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99586a52",
   "metadata": {},
   "source": [
    "Now that we have the 4 lists of county and non-county dataframes from each of the 4 test datasets, we can combine all of the county data into one dataframe and combine all of the non-county data into one dataframe using our *combine_data* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3579b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined_list = combine_data(test_1, test_2, test_3, test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d986dba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001       25508  1971.0     PST0151    AL\n",
       " 3         Baldwin, AL   1003       60141  1971.0     PST0151    AL\n",
       " 4         Barbour, AL   1005       23092  1971.0     PST0151    AL\n",
       " 5            Bibb, AL   1007       13919  1971.0     PST0151    AL\n",
       " 6          Blount, AL   1009       27817  1971.0     PST0151    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037       41226  2009.0     PST0452    WY\n",
       " 31976       Teton, WY  56039       20710  2009.0     PST0452    WY\n",
       " 31977       Uinta, WY  56041       20927  2009.0     PST0452    WY\n",
       " 31978    Washakie, WY  56043        7911  2009.0     PST0452    WY\n",
       " 31979      Weston, WY  56045        7009  2009.0     PST0452    WY\n",
       " \n",
       " [125800 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0   206827028  1971.0     PST0151       ERROR\n",
       " 1            ALABAMA   1000     3497452  1971.0     PST0151  Division 6\n",
       " 69            ALASKA   2000      316494  1971.0     PST0151  Division 9\n",
       " 99           ARIZONA   4000     1896108  1971.0     PST0151  Division 8\n",
       " 115         ARKANSAS   5000     1972028  1971.0     PST0151  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     7882590  2009.0     PST0452  Division 5\n",
       " 31787     WASHINGTON  53000     6664195  2009.0     PST0452  Division 9\n",
       " 31827  WEST VIRGINIA  54000     1819777  2009.0     PST0452  Division 5\n",
       " 31883      WISCONSIN  55000     5654774  2009.0     PST0452  Division 3\n",
       " 31956        WYOMING  56000      544270  2009.0     PST0452  Division 8\n",
       " \n",
       " [2120 rows x 6 columns]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_combined_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b9476",
   "metadata": {},
   "source": [
    "## Part 3: Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a0359",
   "metadata": {},
   "source": [
    "### Subset the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bde1c08",
   "metadata": {},
   "source": [
    "In the next section, we will analyze our data. We want to look only at the non-county data, so we will subset our list of dataframes that we got as output from the combine_data function we made. That function returns a list with the combined county dataframe as the first element and the combined non-county dataframe as the second element. Because list indices start at 0, we will subset the second element using [1]. We will name this new variable **combined_non_county** so we know that it holds the combined dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "308faae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_non_county = combined_enrollment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75aa64fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_name</th>\n",
       "      <th>STCOU</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>year</th>\n",
       "      <th>measurement</th>\n",
       "      <th>division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>0</td>\n",
       "      <td>40024299</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>EDU0101</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1000</td>\n",
       "      <td>733735</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>EDU0101</td>\n",
       "      <td>Division 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ALASKA</td>\n",
       "      <td>2000</td>\n",
       "      <td>102872</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>EDU0101</td>\n",
       "      <td>Division 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>4000</td>\n",
       "      <td>609411</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>EDU0101</td>\n",
       "      <td>Division 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>5000</td>\n",
       "      <td>429260</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>EDU0101</td>\n",
       "      <td>Division 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31650</th>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>51000</td>\n",
       "      <td>1220440</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>EDU0152</td>\n",
       "      <td>Division 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31787</th>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>53000</td>\n",
       "      <td>1026774</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>EDU0152</td>\n",
       "      <td>Division 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31827</th>\n",
       "      <td>WEST VIRGINIA</td>\n",
       "      <td>54000</td>\n",
       "      <td>281938</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>EDU0152</td>\n",
       "      <td>Division 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31883</th>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>55000</td>\n",
       "      <td>876700</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>EDU0152</td>\n",
       "      <td>Division 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31956</th>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56000</td>\n",
       "      <td>85193</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>EDU0152</td>\n",
       "      <td>Division 8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1060 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           area_name  STCOU  enrollment    year measurement    division\n",
       "0      UNITED STATES      0    40024299  1987.0     EDU0101       ERROR\n",
       "1            ALABAMA   1000      733735  1987.0     EDU0101  Division 6\n",
       "69            ALASKA   2000      102872  1987.0     EDU0101  Division 9\n",
       "99           ARIZONA   4000      609411  1987.0     EDU0101  Division 8\n",
       "115         ARKANSAS   5000      429260  1987.0     EDU0101  Division 7\n",
       "...              ...    ...         ...     ...         ...         ...\n",
       "31650       VIRGINIA  51000     1220440  2006.0     EDU0152  Division 5\n",
       "31787     WASHINGTON  53000     1026774  2006.0     EDU0152  Division 9\n",
       "31827  WEST VIRGINIA  54000      281938  2006.0     EDU0152  Division 5\n",
       "31883      WISCONSIN  55000      876700  2006.0     EDU0152  Division 3\n",
       "31956        WYOMING  56000       85193  2006.0     EDU0152  Division 8\n",
       "\n",
       "[1060 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_non_county"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8945ca3d",
   "metadata": {},
   "source": [
    "Now that we just have the non-county data, we also want to remove any rows where there is \"ERROR\" in the division column. This means that we will only be looking at states. We will subset our dataframe by locating the rows where the division column values do not equal \"ERROR.\" We will rename this dataframe to **combined_state** because we are now dealing with just states and not all non-county data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "092aa4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollment</th>\n",
       "      <th>year</th>\n",
       "      <th>division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>733735</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Division 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>102872</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Division 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>609411</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Division 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>429260</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Division 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>4621126</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Division 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31650</th>\n",
       "      <td>1220440</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Division 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31787</th>\n",
       "      <td>1026774</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Division 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31827</th>\n",
       "      <td>281938</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Division 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31883</th>\n",
       "      <td>876700</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Division 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31956</th>\n",
       "      <td>85193</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Division 8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       enrollment    year    division\n",
       "1          733735  1987.0  Division 6\n",
       "69         102872  1987.0  Division 9\n",
       "99         609411  1987.0  Division 8\n",
       "115        429260  1987.0  Division 7\n",
       "191       4621126  1987.0  Division 9\n",
       "...           ...     ...         ...\n",
       "31650     1220440  2006.0  Division 5\n",
       "31787     1026774  2006.0  Division 9\n",
       "31827      281938  2006.0  Division 5\n",
       "31883      876700  2006.0  Division 3\n",
       "31956       85193  2006.0  Division 8\n",
       "\n",
       "[1040 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_state = combined_non_county.loc[combined_non_county[\"division\"] != \"ERROR\",[\"enrollment\", \n",
    "                                                                                     \"year\", \"division\"]]\n",
    "combined_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6dd66e",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c4cb91-2147-401e-87c9-bc95cd4044c0",
   "metadata": {},
   "source": [
    "In this section, we will be creating a SLR model using **year** (X) to predict **enrollment** (y), and a MLR model using **year** (X1) and **division** (X2) to predict **enrollment** (y).\n",
    "\n",
    "To do this, we are creating a function to take an input of defined predictor and response variables, and the last year to be considered. This function will use certain years to fit the data and then predict the next year enrollment. We will start by training the model on the first three years to predict the fourth year. Then, we will train on four years and predict the fifth year, cycling through until we have predicted the last year included in the dataset. The output of the function will be the mean square error of the predictions for the next years. This function is called **mse_LR**. \n",
    "\n",
    "We want this because we are going to test if a simple linear regression model or a multiple linear regression model fits the data better by calulating MSE. Mean-squared error (MSE) measures the amount of error in our statistical models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c769550",
   "metadata": {},
   "source": [
    "To do MLR, we will need to create the dummy variables. We will do this using the **division** column. We will only include the first 8 variables, leaving off \"division 9\" because it is redundant given all others. We use the pd.get_dummies() method to create the dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28a571cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division 1</th>\n",
       "      <th>Division 2</th>\n",
       "      <th>Division 3</th>\n",
       "      <th>Division 4</th>\n",
       "      <th>Division 5</th>\n",
       "      <th>Division 6</th>\n",
       "      <th>Division 7</th>\n",
       "      <th>Division 8</th>\n",
       "      <th>Division 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31650</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31787</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31827</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31883</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31956</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Division 1  Division 2  Division 3  Division 4  Division 5  Division 6  \\\n",
       "1               0           0           0           0           0           1   \n",
       "69              0           0           0           0           0           0   \n",
       "99              0           0           0           0           0           0   \n",
       "115             0           0           0           0           0           0   \n",
       "191             0           0           0           0           0           0   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "31650           0           0           0           0           1           0   \n",
       "31787           0           0           0           0           0           0   \n",
       "31827           0           0           0           0           1           0   \n",
       "31883           0           0           1           0           0           0   \n",
       "31956           0           0           0           0           0           0   \n",
       "\n",
       "       Division 7  Division 8  Division 9  \n",
       "1               0           0           0  \n",
       "69              0           0           1  \n",
       "99              0           1           0  \n",
       "115             1           0           0  \n",
       "191             0           0           1  \n",
       "...           ...         ...         ...  \n",
       "31650           0           0           0  \n",
       "31787           0           0           1  \n",
       "31827           0           0           0  \n",
       "31883           0           0           0  \n",
       "31956           0           1           0  \n",
       "\n",
       "[1040 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data = combined_state[\"division\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1982a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_state[[\"dummy_div_1\", \"dummy_div_2\",\"dummy_div_3\",\n",
    "                \"dummy_div_4\", \"dummy_div_5\", \"dummy_div_6\", \"dummy_div_7\", \n",
    "                \"dummy_div_8\"]]= pd.get_dummies(data = combined_state[\"division\"])[[\"Division 1\",\n",
    "                                                                                    \"Division 2\", \n",
    "                                                                                    \"Division 3\", \n",
    "                                                                                    \"Division 4\", \n",
    "                                                                                    \"Division 5\", \n",
    "                                                                                    \"Division 6\", \n",
    "                                                                                    \"Division 7\", \n",
    "                                                                                    \"Division 8\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef01e7e",
   "metadata": {},
   "source": [
    "Next, we have to define the predictors and response variables for both SLR and MLR that we will use an input for our function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "076904eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLR_predictors = combined_state[[\"year\"]]\n",
    "MLR_predictors = combined_state[[\"year\", \"dummy_div_1\", \"dummy_div_2\", \"dummy_div_3\", \n",
    "                                 \"dummy_div_4\", \"dummy_div_5\", \"dummy_div_6\", \"dummy_div_7\", \"dummy_div_8\"]]\n",
    "both_response = combined_state[[\"enrollment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca9dfd3f-0319-45b8-b55b-04eee29d8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_LR(predictors, response, last_year):\n",
    "    \n",
    "    # We define which years we will use to train the data and which we will use to test the data\n",
    "    x_train=predictors.loc[predictors['year'] <=(last_year)]\n",
    "    x_test=predictors.loc[predictors['year']==last_year+1]\n",
    "    y_train = response.loc[predictors['year'] <=(last_year)]\n",
    "    y_test = response.loc[predictors['year']==last_year+1]\n",
    "    \n",
    "    # We fit the data to the model and calculate MSE for the prediction\n",
    "    reg=linear_model.LinearRegression()\n",
    "    reg.fit(X=x_train, y=y_train)\n",
    "    preds = reg.predict(x_test)\n",
    "    MSE = mean_squared_error(y_test,preds)\n",
    "    \n",
    "    return(round(MSE,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5919b296",
   "metadata": {},
   "source": [
    "Our first function outputs the sequential MSE for each step we are training and predicting. However, we want to know the total MSE of predicting all the years after the 3rd year. To calculate the total MSE, we created a function called **sum_MSE** that will call our **mse_LR** within it and sum the MSE calculated for each step. This function will take in the predictors, response, and the first_year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82710681",
   "metadata": {},
   "source": [
    "To see all of the years that are in the **year** column of the combined_state dataframe, we can use the .unique() method to print out all of the unique values in that column. Doing so we can see that the first year in the dataset or the earliest year is 1987. However, for our mse_LR function, we want our first year to be 1989 because we are using a minimum of the first 3 years to train our model. To make sure we put in the right year, we put an if statement into our function that asks if the year is less than 1989. If it is, we return an error statement. If this year is 1989 or greater, we can calculate MSE. We will test both of these things below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d7798b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_MSE(predictors, response, first_year):\n",
    "    \n",
    "    # Initialize MSE at zero\n",
    "    MSE = 0\n",
    "    \n",
    "    # If the input year provides less than 3 years of data, return an error\n",
    "    if first_year < 1989.0:\n",
    "        print(\"Error: you have not provided more than three years to calculate MSE\") \n",
    "    \n",
    "    # If the input year does provide 3 years of data, we will use it as input into mse_LR to calculate the MSE \n",
    "    # and sum it\n",
    "    else:\n",
    "        years_list = list(combined_state.year.unique())\n",
    "        years_list_2 = [item for item in years_list if item >= first_year]\n",
    "        \n",
    "        for year in years_list_2[0:-1]:\n",
    "            MSE += mse_LR(predictors, response, year)\n",
    "            \n",
    "    return(\"MSE:\", round(MSE,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee5c15c",
   "metadata": {},
   "source": [
    "Now that we have defined both of our functions, we can call them to calculate the MSE for our simple linear regression model (SLR_MSE) and our multuple linear regression model (MLR_MSE). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680680d4",
   "metadata": {},
   "source": [
    "To test whether our function will produce errors when we git it a first_year that is within the first 3 years, we will call it and give it 1987 as the first_year argument. We can see that it gives an error back, so we will give it a different first_year that includes the first 3 years of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d71f84a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: you have not provided more than three years to calculate MSE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('MSE:', 0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_MSE(SLR_predictors, both_response, first_year = 1987)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae059e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MSE:', 17290390796689.8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SLR_MSE = sum_MSE(SLR_predictors, both_response, first_year = 1989)\n",
    "SLR_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b57d114f-3031-406b-a8d5-d8b7fd5b9754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MSE:', 13014125525966.38)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLR_MSE = sum_MSE(MLR_predictors, both_response, first_year = 1989)\n",
    "MLR_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc91a2e",
   "metadata": {},
   "source": [
    "As we can see from our outputs above, there is a greater amount of error with our simple linear regression model. Our multiple linear regression model has a slighlty lower error. This may be due to the fact that we are using both year **and** division to predict enrollment. More variables to predict enrollment works better than using only the year variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec6c03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
