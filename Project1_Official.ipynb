{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eba3f59c-7a37-4b07-ac7b-4345ff7bcef4",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "**Maddy Bursell, Kim McKeever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93118b84-ab2e-4010-9368-4c3f2f813510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import warnings\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fe8e3f",
   "metadata": {},
   "source": [
    "## Part 1: Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f2f65",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd47657-beca-45b4-812b-38e7ea9dcefa",
   "metadata": {},
   "source": [
    "In this project, we will be reading in files that use 2010 US census data. The goal will be to first read in the data and parse it into a format we can use. We will do this using a series of functions for data processing, combining data, and doing cross-validation.  \n",
    "\n",
    "First, we read in the initial census data to examine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c53331e-f72f-4098-b820-e36fe5ceef83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area_name</th>\n",
       "      <th>STCOU</th>\n",
       "      <th>EDU010187F</th>\n",
       "      <th>EDU010187D</th>\n",
       "      <th>EDU010187N1</th>\n",
       "      <th>EDU010187N2</th>\n",
       "      <th>EDU010188F</th>\n",
       "      <th>EDU010188D</th>\n",
       "      <th>EDU010188N1</th>\n",
       "      <th>EDU010188N2</th>\n",
       "      <th>...</th>\n",
       "      <th>EDU010194N1</th>\n",
       "      <th>EDU010194N2</th>\n",
       "      <th>EDU010195F</th>\n",
       "      <th>EDU010195D</th>\n",
       "      <th>EDU010195N1</th>\n",
       "      <th>EDU010195N2</th>\n",
       "      <th>EDU010196F</th>\n",
       "      <th>EDU010196D</th>\n",
       "      <th>EDU010196N1</th>\n",
       "      <th>EDU010196N2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40024299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39967624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43993459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44715737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>733735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>728234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>727989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>736825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autauga, AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>6829</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baldwin, AL</td>\n",
       "      <td>1003</td>\n",
       "      <td>0</td>\n",
       "      <td>16417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barbour, AL</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>5071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Area_name  STCOU  EDU010187F  EDU010187D  EDU010187N1  EDU010187N2  \\\n",
       "0  UNITED STATES      0           0    40024299            0            0   \n",
       "1        ALABAMA   1000           0      733735            0            0   \n",
       "2    Autauga, AL   1001           0        6829            0            0   \n",
       "3    Baldwin, AL   1003           0       16417            0            0   \n",
       "4    Barbour, AL   1005           0        5071            0            0   \n",
       "\n",
       "   EDU010188F  EDU010188D  EDU010188N1  EDU010188N2  ...  EDU010194N1  \\\n",
       "0           0    39967624            0            0  ...            0   \n",
       "1           0      728234            0            0  ...            0   \n",
       "2           0        6900            0            0  ...            0   \n",
       "3           0       16465            0            0  ...            0   \n",
       "4           0        5098            0            0  ...            0   \n",
       "\n",
       "   EDU010194N2  EDU010195F  EDU010195D  EDU010195N1  EDU010195N2  EDU010196F  \\\n",
       "0            0           0    43993459            0            0           0   \n",
       "1            0           0      727989            0            0           0   \n",
       "2            0           0        7568            0            0           0   \n",
       "3            0           0       19961            0            0           0   \n",
       "4            0           0        5017            0            0           0   \n",
       "\n",
       "   EDU010196D  EDU010196N1  EDU010196N2  \n",
       "0    44715737            0            0  \n",
       "1      736825            0            0  \n",
       "2        7834            0            0  \n",
       "3       20699            0            0  \n",
       "4        5053            0            0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_data = pd.read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv\")\n",
    "import_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339dc0ab",
   "metadata": {},
   "source": [
    "We can see that the data contains many columns and many different kinds of variables within columns. It will be helpful to clean up the data to be more understandable before we begin to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba390b",
   "metadata": {},
   "source": [
    "### Create functions to clean and process the data\n",
    "\n",
    "Functions can be extremely useful when you want to process multiple files in the same way. In this section, we will define 5 different functions that will be called in one wrapper function. All of the functions will work to select only the specific columns we want, create new columns we need, and format the data how we want it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef9d53a",
   "metadata": {},
   "source": [
    "In **func_1** we first want to clean up the data by selecting only certain columns and renaming one column. Our step one will be to rename the \"Area_name\" column as \"area_name\" and to grab all of the columns that end in the letter \"D.\" To do this, it is easiest to create a function that we can use on other datasets down the line. In this function, we take in a dataframe as the input and we have an optional argument to name the new column. The default name of the new column is \"enrollment.\" \n",
    "\n",
    "We only want to maintain a few columns with specific parameters: we want 'Area_name', 'STCOU', and any column that ends with the letter 'D'. Since we want to select all columns ending in \"D\", we are locating those names first. Creating a list of desired columns for our modified data frame by using specific coumn names from the import data and by unpacking the list of column names that end with \"D\" that was generated in the previous line. Next, using the `.loc()` method and the desired columns found in 'col_list', we add those columns to our dataframe. Lastly, we will convert our data into long format where each row has only one enrollment value for the column area_name. This will help to get rid of multiple observations in a given row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45dff0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_1(df_1, col_name = \"enrollment\"):\n",
    "    \n",
    "    # Change the column name\n",
    "    df_2 = df_1.rename(columns = {\"Area_name\":\"area_name\"}, inplace = True)\n",
    "    \n",
    "    # Create a list of the column names and an empty list to grab all of the columns ending in \"D\"\n",
    "    cols=list(df_1)\n",
    "    col_names=[]\n",
    "    \n",
    "    # We will use a for loop to iterate through the columns and grab the column names ending in \"D\" into a list\n",
    "    for x in cols:\n",
    "        if x.endswith(\"D\"):\n",
    "            col_names.append(x)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    # We can subset our original dataframe to grab the columns we want with the list \"col_list\"\n",
    "    col_list=['area_name', 'STCOU', *col_names]\n",
    "    df_2=df_1.loc[:,col_list]\n",
    "    \n",
    "    # Convert the dataframe to long format using pd.melt()\n",
    "    df_2 = df_2.melt(id_vars = [\"area_name\", \"STCOU\"], var_name = \"info\", value_name = col_name)\n",
    "    \n",
    "    return(df_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b36b86b",
   "metadata": {},
   "source": [
    "In **func_2**, we are taking the output of func_1 and processing it even more. Each variable in the info column holds important information. The last two characters before the \"D\" represent the year. We want to create a new column called \"year\" that stores the year. The first three characters represent the survey and the next four represent the type of value you have from the survey. We want to capture those first seven characters in another column called \"measurement.\"\n",
    "\n",
    "First, we will create new empty columns in our dataframe. Then, we will loop through the dataframe by the row, find the info column value, and parse out the measurment and the year. the value for each row will be added to the new columns of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fcf6d7-c7d0-4342-8eaf-f64366c8c8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_2(df_2): \n",
    "    \n",
    "    df_2[\"year\"] = np.nan\n",
    "    df_2[\"measurement\"] = np.nan\n",
    "    for row in range(len(df_2)):\n",
    "        thing = df_2.loc[row, \"info\"]\n",
    "        measure = thing[0:7]\n",
    "        if int(thing[7:9])>=23:\n",
    "            yr = \"19\" + str(thing[7:9])\n",
    "        else:\n",
    "            yr= '20'+ str(thing[7:9])\n",
    "        df_2.loc[row,\"year\"] = int(yr)\n",
    "        df_2.loc[row,\"measurement\"] = str(measure)\n",
    "        \n",
    "    return(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66a418",
   "metadata": {},
   "source": [
    "In **func_3**, we are only editing the county-level data. This function will be called within a later function (func_5) once we have split our original dataframe into two new dataframes called county_df and state_df. In func_3, we are taking the county_df and creating a new column in it where we have the state for each row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6a716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_3(dataframe):\n",
    "    \n",
    "    dataframe[\"State\"] = dataframe.loc[:,\"area_name\"].apply(lambda x: x[-2:])\n",
    "    \n",
    "    return(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c351e1",
   "metadata": {},
   "source": [
    "In **func_4**, we are editing only the state-level data. This function will be called in func_5, after we have created the two new dataframes called county_df and state_df. In this function, we will be creating a new column in state_df that included the division for each of the states. We do this by using a function within a function called return_div. This will check if the state is in a certain list, and return the division to the new column in the dataframe using np.vectorize(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f2d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_4(dataframe):\n",
    "    \n",
    "    def return_div(val):\n",
    "        div1 = [\"CONNECTICUT\", 'MAINE','MASSACHUSETTS','NEW HAMPSHIRE','RHODE ISLAND','VERMONT']\n",
    "        div2 = [\"NEW JERSEY\",'NEW YORK','PENNSYLVANIA']\n",
    "        div3 = ['ILLINOIS','INDIANA','MICHIGAN','OHIO','WISCONSIN']\n",
    "        div4 = ['IOWA','KANSAS','MINNESOTA','MISSOURI','NEBRASKA','NORTH DAKOTA','SOUTH DAKOTA']\n",
    "        div5 = ['DELAWARE','FLORIDA','GEORGIA','MARYLAND','NORTH CAROLINA','SOUTH CAROLINA','VIRGINIA','DISTRICT OF COLUMBIA','WEST VIRGINIA']\n",
    "        div6 = ['ALABAMA','KENTUCKY','MISSISSIPPI','TENNESSEE']\n",
    "        div7 = ['ARKANSAS','LOUISIANA','OKLAHOMA','TEXAS']\n",
    "        div8 = ['ARIZONA','COLORADO','IDAHO','NEVADA','MONTANA','NEW MEXICO','UTAH','WYOMING']\n",
    "        div9 = ['ALASKA','CALIFORNIA','HAWAII','OREGON','WASHINGTON']\n",
    "        val = val.upper()\n",
    "    \n",
    "        if val in div1:\n",
    "            return(\"Division 1\")\n",
    "        elif val in div2:\n",
    "            return(\"Division 2\")\n",
    "        elif val in div3:\n",
    "            return(\"Division 3\")\n",
    "        elif val in div4:\n",
    "            return(\"Division 4\")\n",
    "        elif val in div5:\n",
    "            return(\"Division 5\")\n",
    "        elif val in div6:\n",
    "            return(\"Division 6\")\n",
    "        elif val in div7:\n",
    "            return(\"Division 7\")\n",
    "        elif val in div8:\n",
    "            return(\"Division 8\")\n",
    "        elif val in div9:\n",
    "            return(\"Division 9\")\n",
    "        else:\n",
    "            return(\"ERROR\")\n",
    "        \n",
    "    dataframe[\"division\"] = np.vectorize(return_div)(dataframe[\"area_name\"])\n",
    "    return(dataframe)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c109afc9",
   "metadata": {},
   "source": [
    "In **func_5**, we are processing the output from func_2 and creating two new dataframes. We can see that the \"area_name\" column holds two different kinds of values: states and counties of states. We would like to create two separate dataframes that hold the state-level data and the county-level data. To do that, we will create an indexing vector using a lambda function. The lambda function is searching the string within each row, in the 'area_name' column, searching to match if the fourth character of from the end is a `','`. This information is passed into a new column on the data frame that expresses a boolean to identify whether or not the row represented is part of a county or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062d098d-8e99-4b24-a347-0af0e7978a11",
   "metadata": {},
   "source": [
    "Now that there is a new column on `census_df` to index whether or not an area represents a county or not, the two different dataframes are created. The county data frame is generated using `.loc()` and the state dataframe is generated by running `np.logical_not()` method from numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3f485-ca33-41a0-b576-ca2045611a08",
   "metadata": {},
   "source": [
    "The State information was then pulled from the `area_name` column to be held in its own unique column called \"State\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befba0f6",
   "metadata": {},
   "source": [
    "Once we have the two new dataframes, we will call **func_3** on county_df which will add a column called \"state\" specifying the state in each row. We will also call **func_4** on state_df which will add a new column in that dataframe that specifies the division of each state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef225780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_5(dataframe):\n",
    "    \n",
    "    dataframe[\"is_county\"] = dataframe[\"area_name\"].apply(lambda x: x[-4] == \",\")\n",
    "    county_df = dataframe.loc[dataframe[\"is_county\"]]\n",
    "    state_df = dataframe.loc[np.logical_not(dataframe[\"is_county\"])]\n",
    "    \n",
    "    county_df = func_3(county_df)\n",
    "    final_county_df = county_df[[\"area_name\", \"STCOU\", \"enrollment\", \"year\", \"measurement\", \"State\"]]\n",
    "    state_df = func_4(state_df)\n",
    "    final_state_df = state_df[[\"area_name\", \"STCOU\", \"enrollment\", \"year\", \"measurement\", \"division\"]]\n",
    "    \n",
    "    return(final_county_df, final_state_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e034b",
   "metadata": {},
   "source": [
    "### Create a wrapper function that will call all of our previously defined functions\n",
    "\n",
    "If we have several functions that function continuously, meaning the output of one function becomes the input of the next function, we can easily run all of these functions at once by putting them within another function. This saves time and energy, and keeps you from making mistakes while typing in the input for each individual function. In our wrapper function, we give the argument for the data to read in and then all of the functions will run, leaving us with our desired output. Because the wrapper function does most of the data processing steps, we have named it \"data_processing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dfe1b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(URL, col_name = \"enrollment\"):\n",
    "    \n",
    "    import_data = pd.read_csv(URL)\n",
    "    census_df = func_1(import_data)\n",
    "    census_df_2 = func_2(census_df)\n",
    "    county_df, state_df = func_5(census_df_2)\n",
    "    \n",
    "    return([county_df, state_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31428a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cq/wkd76m4s1mb9xtzp3mp6kf140000gn/T/ipykernel_9338/23138269.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"State\"] = dataframe.loc[:,\"area_name\"].apply(lambda x: x[-2:])\n",
      "/var/folders/cq/wkd76m4s1mb9xtzp3mp6kf140000gn/T/ipykernel_9338/2953892804.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"division\"] = np.vectorize(return_div)(dataframe[\"area_name\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001        6829  1987.0     EDU0101    AL\n",
       " 3         Baldwin, AL   1003       16417  1987.0     EDU0101    AL\n",
       " 4         Barbour, AL   1005        5071  1987.0     EDU0101    AL\n",
       " 5            Bibb, AL   1007        3557  1987.0     EDU0101    AL\n",
       " 6          Blount, AL   1009        7319  1987.0     EDU0101    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037        9599  1996.0     EDU0101    WY\n",
       " 31976       Teton, WY  56039        2226  1996.0     EDU0101    WY\n",
       " 31977       Uinta, WY  56041        5750  1996.0     EDU0101    WY\n",
       " 31978    Washakie, WY  56043        1900  1996.0     EDU0101    WY\n",
       " 31979      Weston, WY  56045        1479  1996.0     EDU0101    WY\n",
       " \n",
       " [31450 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0    40024299  1987.0     EDU0101       ERROR\n",
       " 1            ALABAMA   1000      733735  1987.0     EDU0101  Division 6\n",
       " 69            ALASKA   2000      102872  1987.0     EDU0101  Division 9\n",
       " 99           ARIZONA   4000      609411  1987.0     EDU0101  Division 8\n",
       " 115         ARKANSAS   5000      429260  1987.0     EDU0101  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     1079854  1996.0     EDU0101  Division 5\n",
       " 31787     WASHINGTON  53000      956572  1996.0     EDU0101  Division 9\n",
       " 31827  WEST VIRGINIA  54000      307112  1996.0     EDU0101  Division 5\n",
       " 31883      WISCONSIN  55000      870175  1996.0     EDU0101  Division 3\n",
       " 31956        WYOMING  56000       99859  1996.0     EDU0101  Division 8\n",
       " \n",
       " [530 rows x 6 columns]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_1 = data_processing(\"https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv\")\n",
    "file_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "393a3a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cq/wkd76m4s1mb9xtzp3mp6kf140000gn/T/ipykernel_9338/23138269.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"State\"] = dataframe.loc[:,\"area_name\"].apply(lambda x: x[-2:])\n",
      "/var/folders/cq/wkd76m4s1mb9xtzp3mp6kf140000gn/T/ipykernel_9338/2953892804.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"division\"] = np.vectorize(return_div)(dataframe[\"area_name\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001        8099  1997.0     EDU0101    AL\n",
       " 3         Baldwin, AL   1003       21410  1997.0     EDU0101    AL\n",
       " 4         Barbour, AL   1005        5100  1997.0     EDU0101    AL\n",
       " 5            Bibb, AL   1007        3717  1997.0     EDU0101    AL\n",
       " 6          Blount, AL   1009        7816  1997.0     EDU0101    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037        6964  2006.0     EDU0152    WY\n",
       " 31976       Teton, WY  56039        2264  2006.0     EDU0152    WY\n",
       " 31977       Uinta, WY  56041        4298  2006.0     EDU0152    WY\n",
       " 31978    Washakie, WY  56043        1410  2006.0     EDU0152    WY\n",
       " 31979      Weston, WY  56045        1076  2006.0     EDU0152    WY\n",
       " \n",
       " [31450 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0    44534459  1997.0     EDU0101       ERROR\n",
       " 1            ALABAMA   1000      737386  1997.0     EDU0101  Division 6\n",
       " 69            ALASKA   2000      129919  1997.0     EDU0101  Division 9\n",
       " 99           ARIZONA   4000      798069  1997.0     EDU0101  Division 8\n",
       " 115         ARKANSAS   5000      459787  1997.0     EDU0101  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     1220440  2006.0     EDU0152  Division 5\n",
       " 31787     WASHINGTON  53000     1026774  2006.0     EDU0152  Division 9\n",
       " 31827  WEST VIRGINIA  54000      281938  2006.0     EDU0152  Division 5\n",
       " 31883      WISCONSIN  55000      876700  2006.0     EDU0152  Division 3\n",
       " 31956        WYOMING  56000       85193  2006.0     EDU0152  Division 8\n",
       " \n",
       " [530 rows x 6 columns]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_2 = data_processing(\"https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv\")\n",
    "file_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0822a5da",
   "metadata": {},
   "source": [
    "## Part 2: Combine Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fd69c5",
   "metadata": {},
   "source": [
    "### Combine county and state data from multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c15c4a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(*files):\n",
    "    county_data = list(map(lambda x: x[0], files))\n",
    "    state_data = map(lambda x: x[1], files)\n",
    "\n",
    "    combine_county = functools.reduce(lambda x,y: pd.concat([x,y]), county_data)\n",
    "    combine_state = functools.reduce(lambda x,y: pd.concat([x,y]), state_data)\n",
    "    \n",
    "    return([combine_county, combine_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0f1f199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001        6829  1987.0     EDU0101    AL\n",
       " 3         Baldwin, AL   1003       16417  1987.0     EDU0101    AL\n",
       " 4         Barbour, AL   1005        5071  1987.0     EDU0101    AL\n",
       " 5            Bibb, AL   1007        3557  1987.0     EDU0101    AL\n",
       " 6          Blount, AL   1009        7319  1987.0     EDU0101    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037        6964  2006.0     EDU0152    WY\n",
       " 31976       Teton, WY  56039        2264  2006.0     EDU0152    WY\n",
       " 31977       Uinta, WY  56041        4298  2006.0     EDU0152    WY\n",
       " 31978    Washakie, WY  56043        1410  2006.0     EDU0152    WY\n",
       " 31979      Weston, WY  56045        1076  2006.0     EDU0152    WY\n",
       " \n",
       " [62900 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0    40024299  1987.0     EDU0101       ERROR\n",
       " 1            ALABAMA   1000      733735  1987.0     EDU0101  Division 6\n",
       " 69            ALASKA   2000      102872  1987.0     EDU0101  Division 9\n",
       " 99           ARIZONA   4000      609411  1987.0     EDU0101  Division 8\n",
       " 115         ARKANSAS   5000      429260  1987.0     EDU0101  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     1220440  2006.0     EDU0152  Division 5\n",
       " 31787     WASHINGTON  53000     1026774  2006.0     EDU0152  Division 9\n",
       " 31827  WEST VIRGINIA  54000      281938  2006.0     EDU0152  Division 5\n",
       " 31883      WISCONSIN  55000      876700  2006.0     EDU0152  Division 3\n",
       " 31956        WYOMING  56000       85193  2006.0     EDU0152  Division 8\n",
       " \n",
       " [1060 rows x 6 columns]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_enrollment = combine_data(file_1, file_2)\n",
    "combined_enrollment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d46ed9",
   "metadata": {},
   "source": [
    "### Check if it generalizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01825ab",
   "metadata": {},
   "source": [
    "We have seen that our data processing functions work on the files labeled \"EDU01a\" and \"EDU01b\", now we will check to see if our functions are generalized enough to work on multiple new files. We will import 4 new files using their URLs. \n",
    "\n",
    "Let's begin by running our wrapping function \"data_processing\" on the four new files to create 4 lists of county and state dataframes. We will name these additional files \"test\" so that we can distinguish them from the main two files we have been working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f67f5fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cq/wkd76m4s1mb9xtzp3mp6kf140000gn/T/ipykernel_9338/23138269.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"State\"] = dataframe.loc[:,\"area_name\"].apply(lambda x: x[-2:])\n",
      "/var/folders/cq/wkd76m4s1mb9xtzp3mp6kf140000gn/T/ipykernel_9338/2953892804.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"division\"] = np.vectorize(return_div)(dataframe[\"area_name\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001       25508  1971.0     PST0151    AL\n",
       " 3         Baldwin, AL   1003       60141  1971.0     PST0151    AL\n",
       " 4         Barbour, AL   1005       23092  1971.0     PST0151    AL\n",
       " 5            Bibb, AL   1007       13919  1971.0     PST0151    AL\n",
       " 6          Blount, AL   1009       27817  1971.0     PST0151    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037       44284  1981.0     PST0251    WY\n",
       " 31976       Teton, WY  56039       10015  1981.0     PST0251    WY\n",
       " 31977       Uinta, WY  56041       16277  1981.0     PST0251    WY\n",
       " 31978    Washakie, WY  56043        9927  1981.0     PST0251    WY\n",
       " 31979      Weston, WY  56045        7508  1981.0     PST0251    WY\n",
       " \n",
       " [31450 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0   206827028  1971.0     PST0151       ERROR\n",
       " 1            ALABAMA   1000     3497452  1971.0     PST0151  Division 6\n",
       " 69            ALASKA   2000      316494  1971.0     PST0151  Division 9\n",
       " 99           ARIZONA   4000     1896108  1971.0     PST0151  Division 8\n",
       " 115         ARKANSAS   5000     1972028  1971.0     PST0151  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     5444155  1981.0     PST0251  Division 5\n",
       " 31787     WASHINGTON  53000     4235733  1981.0     PST0251  Division 9\n",
       " 31827  WEST VIRGINIA  54000     1954105  1981.0     PST0251  Division 5\n",
       " 31883      WISCONSIN  55000     4726315  1981.0     PST0251  Division 3\n",
       " 31956        WYOMING  56000      491700  1981.0     PST0251  Division 8\n",
       " \n",
       " [530 rows x 6 columns]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 = data_processing(\"https://www4.stat.ncsu.edu/~online/datasets/PST01a.csv\")\n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d018e8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cq/wkd76m4s1mb9xtzp3mp6kf140000gn/T/ipykernel_9338/23138269.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"State\"] = dataframe.loc[:,\"area_name\"].apply(lambda x: x[-2:])\n",
      "/var/folders/cq/wkd76m4s1mb9xtzp3mp6kf140000gn/T/ipykernel_9338/2953892804.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"division\"] = np.vectorize(return_div)(dataframe[\"area_name\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001       32038  1982.0     PST0251    AL\n",
       " 3         Baldwin, AL   1003       82330  1982.0     PST0251    AL\n",
       " 4         Barbour, AL   1005       24775  1982.0     PST0251    AL\n",
       " 5            Bibb, AL   1007       16017  1982.0     PST0251    AL\n",
       " 6          Blount, AL   1009       36356  1982.0     PST0251    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037       38792  1990.0     PST0351    WY\n",
       " 31976       Teton, WY  56039       11328  1990.0     PST0351    WY\n",
       " 31977       Uinta, WY  56041       18638  1990.0     PST0351    WY\n",
       " 31978    Washakie, WY  56043        8363  1990.0     PST0351    WY\n",
       " 31979      Weston, WY  56045        6506  1990.0     PST0351    WY\n",
       " \n",
       " [31450 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0   231665106  1982.0     PST0251       ERROR\n",
       " 1            ALABAMA   1000     3925328  1982.0     PST0251  Division 6\n",
       " 69            ALASKA   2000      449608  1982.0     PST0251  Division 9\n",
       " 99           ARIZONA   4000     2889877  1982.0     PST0251  Division 8\n",
       " 115         ARKANSAS   5000     2294297  1982.0     PST0251  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     6216884  1990.0     PST0351  Division 5\n",
       " 31787     WASHINGTON  53000     4903043  1990.0     PST0351  Division 9\n",
       " 31827  WEST VIRGINIA  54000     1792548  1990.0     PST0351  Division 5\n",
       " 31883      WISCONSIN  55000     4904562  1990.0     PST0351  Division 3\n",
       " 31956        WYOMING  56000      453690  1990.0     PST0351  Division 8\n",
       " \n",
       " [530 rows x 6 columns]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2 = data_processing(\"https://www4.stat.ncsu.edu/~online/datasets/PST01b.csv\")\n",
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f38f47dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cq/wkd76m4s1mb9xtzp3mp6kf140000gn/T/ipykernel_9338/23138269.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"State\"] = dataframe.loc[:,\"area_name\"].apply(lambda x: x[-2:])\n",
      "/var/folders/cq/wkd76m4s1mb9xtzp3mp6kf140000gn/T/ipykernel_9338/2953892804.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"division\"] = np.vectorize(return_div)(dataframe[\"area_name\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001       35010  1991.0     PST0351    AL\n",
       " 3         Baldwin, AL   1003      102420  1991.0     PST0351    AL\n",
       " 4         Barbour, AL   1005       26506  1991.0     PST0351    AL\n",
       " 5            Bibb, AL   1007       17071  1991.0     PST0351    AL\n",
       " 6          Blount, AL   1009       40190  1991.0     PST0351    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037       37613  2000.0     PST0402    WY\n",
       " 31976       Teton, WY  56039       18250  2000.0     PST0402    WY\n",
       " 31977       Uinta, WY  56041       19742  2000.0     PST0402    WY\n",
       " 31978    Washakie, WY  56043        8291  2000.0     PST0402    WY\n",
       " 31979      Weston, WY  56045        6644  2000.0     PST0402    WY\n",
       " \n",
       " [31450 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0   252980941  1991.0     PST0351       ERROR\n",
       " 1            ALABAMA   1000     4099156  1991.0     PST0351  Division 6\n",
       " 69            ALASKA   2000      570193  1991.0     PST0351  Division 9\n",
       " 99           ARIZONA   4000     3788576  1991.0     PST0351  Division 8\n",
       " 115         ARKANSAS   5000     2383144  1991.0     PST0351  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     7079048  2000.0     PST0402  Division 5\n",
       " 31787     WASHINGTON  53000     5894143  2000.0     PST0402  Division 9\n",
       " 31827  WEST VIRGINIA  54000     1808344  2000.0     PST0402  Division 5\n",
       " 31883      WISCONSIN  55000     5363708  2000.0     PST0402  Division 3\n",
       " 31956        WYOMING  56000      493783  2000.0     PST0402  Division 8\n",
       " \n",
       " [530 rows x 6 columns]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3 = data_processing(\"https://www4.stat.ncsu.edu/~online/datasets/PST01c.csv\")\n",
    "test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7288943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cq/wkd76m4s1mb9xtzp3mp6kf140000gn/T/ipykernel_9338/23138269.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"State\"] = dataframe.loc[:,\"area_name\"].apply(lambda x: x[-2:])\n",
      "/var/folders/cq/wkd76m4s1mb9xtzp3mp6kf140000gn/T/ipykernel_9338/2953892804.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"division\"] = np.vectorize(return_div)(dataframe[\"area_name\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[            area_name  STCOU  enrollment    year measurement State\n",
       " 2         Autauga, AL   1001       43872  2000.0     PST0452    AL\n",
       " 3         Baldwin, AL   1003      141358  2000.0     PST0452    AL\n",
       " 4         Barbour, AL   1005       29035  2000.0     PST0452    AL\n",
       " 5            Bibb, AL   1007       19936  2000.0     PST0452    AL\n",
       " 6          Blount, AL   1009       51181  2000.0     PST0452    AL\n",
       " ...               ...    ...         ...     ...         ...   ...\n",
       " 31975  Sweetwater, WY  56037       41226  2009.0     PST0452    WY\n",
       " 31976       Teton, WY  56039       20710  2009.0     PST0452    WY\n",
       " 31977       Uinta, WY  56041       20927  2009.0     PST0452    WY\n",
       " 31978    Washakie, WY  56043        7911  2009.0     PST0452    WY\n",
       " 31979      Weston, WY  56045        7009  2009.0     PST0452    WY\n",
       " \n",
       " [31450 rows x 6 columns],\n",
       "            area_name  STCOU  enrollment    year measurement    division\n",
       " 0      UNITED STATES      0   282171957  2000.0     PST0452       ERROR\n",
       " 1            ALABAMA   1000     4451849  2000.0     PST0452  Division 6\n",
       " 69            ALASKA   2000      627499  2000.0     PST0452  Division 9\n",
       " 99           ARIZONA   4000     5166697  2000.0     PST0452  Division 8\n",
       " 115         ARKANSAS   5000     2678288  2000.0     PST0452  Division 7\n",
       " ...              ...    ...         ...     ...         ...         ...\n",
       " 31650       VIRGINIA  51000     7882590  2009.0     PST0452  Division 5\n",
       " 31787     WASHINGTON  53000     6664195  2009.0     PST0452  Division 9\n",
       " 31827  WEST VIRGINIA  54000     1819777  2009.0     PST0452  Division 5\n",
       " 31883      WISCONSIN  55000     5654774  2009.0     PST0452  Division 3\n",
       " 31956        WYOMING  56000      544270  2009.0     PST0452  Division 8\n",
       " \n",
       " [530 rows x 6 columns]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_4 = data_processing(\"https://www4.stat.ncsu.edu/~online/datasets/PST01d.csv\")\n",
    "test_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99586a52",
   "metadata": {},
   "source": [
    "Now that we have the 4 lists of county and state dataframes from each of the 4 test datasets, we can combine all of the county data into one dataframe and combine all of the state data into one dataframe using our combine_data function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3579b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_county, test_state = combine_data(test_1, test_2, test_3, test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d986dba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 125800 entries, 2 to 31979\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   area_name    125800 non-null  object \n",
      " 1   STCOU        125800 non-null  int64  \n",
      " 2   enrollment   125800 non-null  int64  \n",
      " 3   year         125800 non-null  float64\n",
      " 4   measurement  125800 non-null  object \n",
      " 5   State        125800 non-null  object \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "test_county.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b12c5844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2120 entries, 0 to 31956\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   area_name    2120 non-null   object \n",
      " 1   STCOU        2120 non-null   int64  \n",
      " 2   enrollment   2120 non-null   int64  \n",
      " 3   year         2120 non-null   float64\n",
      " 4   measurement  2120 non-null   object \n",
      " 5   division     2120 non-null   object \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 115.9+ KB\n"
     ]
    }
   ],
   "source": [
    "test_state.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b9476",
   "metadata": {},
   "source": [
    "## Part 3: Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a0359",
   "metadata": {},
   "source": [
    "### Subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "308faae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_county = combined_enrollment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75aa64fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_name</th>\n",
       "      <th>STCOU</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>year</th>\n",
       "      <th>measurement</th>\n",
       "      <th>division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>0</td>\n",
       "      <td>40024299</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>EDU0101</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1000</td>\n",
       "      <td>733735</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>EDU0101</td>\n",
       "      <td>Division 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ALASKA</td>\n",
       "      <td>2000</td>\n",
       "      <td>102872</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>EDU0101</td>\n",
       "      <td>Division 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>4000</td>\n",
       "      <td>609411</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>EDU0101</td>\n",
       "      <td>Division 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>5000</td>\n",
       "      <td>429260</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>EDU0101</td>\n",
       "      <td>Division 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31650</th>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>51000</td>\n",
       "      <td>1220440</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>EDU0152</td>\n",
       "      <td>Division 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31787</th>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>53000</td>\n",
       "      <td>1026774</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>EDU0152</td>\n",
       "      <td>Division 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31827</th>\n",
       "      <td>WEST VIRGINIA</td>\n",
       "      <td>54000</td>\n",
       "      <td>281938</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>EDU0152</td>\n",
       "      <td>Division 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31883</th>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>55000</td>\n",
       "      <td>876700</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>EDU0152</td>\n",
       "      <td>Division 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31956</th>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56000</td>\n",
       "      <td>85193</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>EDU0152</td>\n",
       "      <td>Division 8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1060 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           area_name  STCOU  enrollment    year measurement    division\n",
       "0      UNITED STATES      0    40024299  1987.0     EDU0101       ERROR\n",
       "1            ALABAMA   1000      733735  1987.0     EDU0101  Division 6\n",
       "69            ALASKA   2000      102872  1987.0     EDU0101  Division 9\n",
       "99           ARIZONA   4000      609411  1987.0     EDU0101  Division 8\n",
       "115         ARKANSAS   5000      429260  1987.0     EDU0101  Division 7\n",
       "...              ...    ...         ...     ...         ...         ...\n",
       "31650       VIRGINIA  51000     1220440  2006.0     EDU0152  Division 5\n",
       "31787     WASHINGTON  53000     1026774  2006.0     EDU0152  Division 9\n",
       "31827  WEST VIRGINIA  54000      281938  2006.0     EDU0152  Division 5\n",
       "31883      WISCONSIN  55000      876700  2006.0     EDU0152  Division 3\n",
       "31956        WYOMING  56000       85193  2006.0     EDU0152  Division 8\n",
       "\n",
       "[1060 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "092aa4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollment</th>\n",
       "      <th>year</th>\n",
       "      <th>division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>733735</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Division 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>102872</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Division 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>609411</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Division 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>429260</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Division 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>4621126</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Division 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31650</th>\n",
       "      <td>1220440</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Division 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31787</th>\n",
       "      <td>1026774</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Division 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31827</th>\n",
       "      <td>281938</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Division 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31883</th>\n",
       "      <td>876700</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Division 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31956</th>\n",
       "      <td>85193</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Division 8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       enrollment    year    division\n",
       "1          733735  1987.0  Division 6\n",
       "69         102872  1987.0  Division 9\n",
       "99         609411  1987.0  Division 8\n",
       "115        429260  1987.0  Division 7\n",
       "191       4621126  1987.0  Division 9\n",
       "...           ...     ...         ...\n",
       "31650     1220440  2006.0  Division 5\n",
       "31787     1026774  2006.0  Division 9\n",
       "31827      281938  2006.0  Division 5\n",
       "31883      876700  2006.0  Division 3\n",
       "31956       85193  2006.0  Division 8\n",
       "\n",
       "[1040 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_county = non_county.loc[non_county[\"division\"] != \"ERROR\",[\"enrollment\", \"year\", \"division\"]]\n",
    "non_county"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c600990",
   "metadata": {},
   "source": [
    "### Simple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b175715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19815214.959094852 [10355.98042221]\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X = non_county[\"year\"].values.reshape(-1,1), y = non_county[\"enrollment\"].values)\n",
    "print(reg.intercept_, reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbd64ffb-3d57-406d-b593-e6357db0d972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subsetting three years of data\n",
    "subset_3yr=non_county.loc[non_county['year'] <(min(non_county['year']+3))]\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(X=subset_3yr[\"year\"].values.reshape(-1,1), y=subset_3yr[\"enrollment\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d17d0e4f-4c89-474c-bf06-c546ca126e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4821369.583 2814.0\n"
     ]
    }
   ],
   "source": [
    "#estimating intercept and slope of simple linear regression\n",
    "print(round(reg.intercept_,3), round(reg.coef_[0],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea7c2ec7-6030-4814-bdaf-0382d864fbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[778490.41666667]\n"
     ]
    }
   ],
   "source": [
    "#predicting future data\n",
    "pred_3yr=reg.predict([[1990]])\n",
    "print(pred_3yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ac9a6b-edac-479a-a27b-a8d5b64cd550",
   "metadata": {},
   "source": [
    "Chart of simple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d855638d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='year', ylabel='enrollment'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x = non_county[\"year\"], y = non_county[\"enrollment\"], scatter_kws = {\"s\":2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a110f7",
   "metadata": {},
   "source": [
    "### Multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "444fa253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division 1</th>\n",
       "      <th>Division 2</th>\n",
       "      <th>Division 3</th>\n",
       "      <th>Division 4</th>\n",
       "      <th>Division 5</th>\n",
       "      <th>Division 6</th>\n",
       "      <th>Division 7</th>\n",
       "      <th>Division 8</th>\n",
       "      <th>Division 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31650</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31787</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31827</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31883</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31956</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Division 1  Division 2  Division 3  Division 4  Division 5  Division 6  \\\n",
       "1               0           0           0           0           0           1   \n",
       "69              0           0           0           0           0           0   \n",
       "99              0           0           0           0           0           0   \n",
       "115             0           0           0           0           0           0   \n",
       "191             0           0           0           0           0           0   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "31650           0           0           0           0           1           0   \n",
       "31787           0           0           0           0           0           0   \n",
       "31827           0           0           0           0           1           0   \n",
       "31883           0           0           1           0           0           0   \n",
       "31956           0           0           0           0           0           0   \n",
       "\n",
       "       Division 7  Division 8  Division 9  \n",
       "1               0           0           0  \n",
       "69              0           0           1  \n",
       "99              0           1           0  \n",
       "115             1           0           0  \n",
       "191             0           0           1  \n",
       "...           ...         ...         ...  \n",
       "31650           0           0           0  \n",
       "31787           0           0           1  \n",
       "31827           0           0           0  \n",
       "31883           0           0           0  \n",
       "31956           0           1           0  \n",
       "\n",
       "[1040 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data = non_county[\"division\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe4d2946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing MLR\n",
    "#mlr_fit = linear_model.LinearRegression()\n",
    "#mlr_fit.fit(non_county[[\"year\", \"dummy_div_1\", \"dummy_div_2\", \"dummy_div_3\", \"dummy_div_4\", \"dummy_div_5\", \"dummy_div_6\", \"dummy_div_7\", \"dummy_div_8\"]], non_county[\"enrollment\"].values)\n",
    "#print(mlr_fit.intercept_, mlr_fit.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6dd66e",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c4cb91-2147-401e-87c9-bc95cd4044c0",
   "metadata": {},
   "source": [
    "Creating a function to take an input of a dataframe, defined prediction and response variables, and the last year to be considered. This function outputs the mean square error and mean error of the prediction for the next year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c769550",
   "metadata": {},
   "source": [
    "Create the dummy variables we will use to do multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1982a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_county[[\"dummy_div_1\", \"dummy_div_2\", \"dummy_div_3\", \"dummy_div_4\", \"dummy_div_5\", \"dummy_div_6\", \"dummy_div_7\", \"dummy_div_8\"]] = pd.get_dummies(data = non_county[\"division\"])[[\"Division 1\", \"Division 2\", \"Division 3\", \"Division 4\", \"Division 5\", \"Division 6\", \"Division 7\", \"Division 8\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "076904eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9595</th>\n",
       "      <td>1990.0</td>\n",
       "      <td>728252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9663</th>\n",
       "      <td>1990.0</td>\n",
       "      <td>108810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9693</th>\n",
       "      <td>1990.0</td>\n",
       "      <td>617753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9709</th>\n",
       "      <td>1990.0</td>\n",
       "      <td>436023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9785</th>\n",
       "      <td>1990.0</td>\n",
       "      <td>4771978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31650</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>1220440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31787</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>1026774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31827</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>281938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31883</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>876700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31956</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>85193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>884 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  enrollment\n",
       "9595   1990.0      728252\n",
       "9663   1990.0      108810\n",
       "9693   1990.0      617753\n",
       "9709   1990.0      436023\n",
       "9785   1990.0     4771978\n",
       "...       ...         ...\n",
       "31650  2006.0     1220440\n",
       "31787  2006.0     1026774\n",
       "31827  2006.0      281938\n",
       "31883  2006.0      876700\n",
       "31956  2006.0       85193\n",
       "\n",
       "[884 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SLR_predictors = non_county[[\"year\"]]\n",
    "MLR_predictors = non_county[[\"year\", \"dummy_div_1\", \"dummy_div_2\", \"dummy_div_3\", \"dummy_div_4\", \"dummy_div_5\", \"dummy_div_6\", \"dummy_div_7\", \"dummy_div_8\"]]\n",
    "subset_nc = non_county[[\"year\", \"enrollment\"]]\n",
    "cont = subset_nc[subset_nc[\"year\"] > 1989.0]\n",
    "both_response = non_county[[\"enrollment\"]]\n",
    "cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "80f867df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>733735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>102872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>609411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>429260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>4621126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31650</th>\n",
       "      <td>1220440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31787</th>\n",
       "      <td>1026774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31827</th>\n",
       "      <td>281938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31883</th>\n",
       "      <td>876700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31956</th>\n",
       "      <td>85193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       enrollment\n",
       "1          733735\n",
       "69         102872\n",
       "99         609411\n",
       "115        429260\n",
       "191       4621126\n",
       "...           ...\n",
       "31650     1220440\n",
       "31787     1026774\n",
       "31827      281938\n",
       "31883      876700\n",
       "31956       85193\n",
       "\n",
       "[1040 rows x 1 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca9dfd3f-0319-45b8-b55b-04eee29d8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_SLR_MLR(predictors, response, last_year):\n",
    "    subset_train=predictors.loc[predictors['year'] <=(last_year)]\n",
    "    subset_test=predictors.loc[predictors['year']==last_year+1]\n",
    "    reg=linear_model.LinearRegression()\n",
    "    reg.fit(X=subset_train.values.reshape(-1,1), y=response.values)\n",
    "    preds = reg.predict(subset_test.values.reshape(-1,1))\n",
    "    MSE = mean_squared_error(response,preds)\n",
    "    sqrt=math.sqrt(MSE)\n",
    "    print('MSE =',round(MSE,2))\n",
    "    print('mean error= ',round(sqrt,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d7798b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_MSE(predictors, response, first_year):\n",
    "    years_list = list(non_county.year.unique())\n",
    "    MSE = 0\n",
    "    for first_year in years_list:\n",
    "        if first_year < 1989.0:\n",
    "            print(\"Error: you have not provided more than three years to calculate MSE\")\n",
    "            continue\n",
    "        else:\n",
    "            MSE += mse_SLR_MLR(predictors, response, first_year)\n",
    "            \n",
    "    return(\"MSE:\", MSE)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8da5cb3-0dd9-4b01-b1de-bdb45313fa89",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [156, 1040]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cq/wkd76m4s1mb9xtzp3mp6kf140000gn/T/ipykernel_9338/3724120203.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmse_SLR_MLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSLR_predictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboth_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_year\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1989\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/cq/wkd76m4s1mb9xtzp3mp6kf140000gn/T/ipykernel_9338/667304525.py\u001b[0m in \u001b[0;36mmse_SLR_MLR\u001b[0;34m(predictors, response, last_year)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msubset_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlast_year\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    519\u001b[0m                                    y_numeric=True, multi_output=True)\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [156, 1040]"
     ]
    }
   ],
   "source": [
    "mse_SLR_MLR(SLR_predictors, both_response, last_year=1989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15ff4451-c24f-49ed-a873-3578c97ff3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 772730062771.74\n",
      "mean error=  879050.66\n"
     ]
    }
   ],
   "source": [
    "mse_SLR(non_county, predictors='year', response='enrollment', last_year=1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d4f6de9-f938-4a7d-9d5a-7bb973359405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 818824706572.34\n",
      "mean error=  904889.33\n"
     ]
    }
   ],
   "source": [
    "mse_SLR(non_county, predictors='year', response='enrollment', last_year=1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e51f8a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_3 = non_county.loc[non_county[\"year\"] < min(non_county[\"year\"] + 3)]\n",
    "#test_3 = non_county.loc[non_county[\"year\"][:,1990]\n",
    "#test_3.year.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c5c8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(non_county[[\"year\", \"dummy_div_1\", \"dummy_div_2\", \"dummy_div_3\", \"dummy_div_4\", \"dummy_div_5\", \"dummy_div_6\", \"dummy_div_7\", \"dummy_div_8\"]], non_county[\"enrollment\"], test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7ed8924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1987., 1987., 1987., ..., 2006., 2006., 2006.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_county.year.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b189491",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
